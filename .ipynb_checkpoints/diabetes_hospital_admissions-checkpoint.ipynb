{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diabetes 130-US hospitals for years 1999-2008"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset consists of hospital admissions of length between one and 14 days that did not result in a patient death or discharge to a hospice. Each encounter corresponds to a unique patient diagnosed with diabetes, although the primary diagnosis may be different. During each of the analyzed encounters, lab tests were ordered and medication was administered.\n",
    "Since we are primarily interested in factors that lead to early readmission, we defined the readmission attribute (outcome) as having two values: “readmitted,” if the patient was readmitted within 30 days of discharge or “otherwise,” which covers both readmission after 30 days and no readmission at all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Data Set Description**\n",
    "* ***Encounter ID***: Unique identifier of an encounter\n",
    "* ***Patient number***: Unique identifier of a patient\n",
    "* ***Race Values***: Caucasian, Asian, African American, Hispanic, and other\n",
    "* ***Gender Values***: male, female, and unknown/invalid\n",
    "* ***Age***: Grouped in 10-year intervals: 0, 10), 10, 20), …, 90, 100)\n",
    "* ***Weight***: Weight in pounds\n",
    "* ***Admission type***: Integer identifier corresponding to 9 distinct values, for example, emergency, urgent, elective, newborn, and not available\n",
    "* ***Discharge disposition***: Integer identifier corresponding to 29 distinct values, for example, discharged to home, expired, and not available\n",
    "* ***Admission source***: Integer identifier corresponding to 21 distinct values, for example, physician referral, emergency room, and transfer from a hospital\n",
    "* ***Time in hospital***: Integer number of days between admission and discharge\n",
    "* ***Payer code***: Integer identifier corresponding to 23 distinct values, for example, Blue Cross/Blue Shield, Medicare, and self-pay Medical\n",
    "* ***Medical specialty***: Integer identifier of a specialty of the admitting physician, corresponding to 84 distinct values, for example, cardiology, internal medicine, family/general practice, and surgeon\n",
    "* ***Number of lab procedures***: Number of lab tests performed during the encounter\n",
    "* ***Number of procedures***: Numeric Number of procedures (other than lab tests) performed during the encounter\n",
    "* ***Number of medications***: Number of distinct generic names administered during the encounter\n",
    "* ***Number of outpatient visits***: Number of outpatient visits of the patient in the year preceding the encounter\n",
    "* ***Number of emergency visits***: Number of emergency visits of the patient in the year preceding the encounter\n",
    "* ***Number of inpatient visits***: Number of inpatient visits of the patient in the year preceding the encounter\n",
    "* ***Diagnosis 1***: The primary diagnosis (coded as first three digits of ICD9); 848 distinct values\n",
    "* ***Diagnosis 2***: Secondary diagnosis (coded as first three digits of ICD9); 923 distinct values\n",
    "* ***Diagnosis 3***: Additional secondary diagnosis (coded as first three digits of ICD9); 954 distinct values\n",
    "* ***Number of diagnoses***: Number of diagnoses entered to the system 0%\n",
    "* ***Glucose serum test***: result Indicates the range of the result or if the test was not taken. Values: “>200,” “>300,” “normal,” and “none” if not measured\n",
    "* ***A1c test result***: Indicates the range of the result or if the test was not taken. Values: “>8” if the result was greater than 8%, “>7” if the result was greater than 7% but less than 8%, “normal” if the result was less than 7%, and “none” if not measured.\n",
    "Change of medications Indicates if there was a change in diabetic medications (either dosage or generic name). Values: “change” and “no change”\n",
    "* ***Diabetes medications***: Indicates if there was any diabetic medication prescribed. Values: “yes” and “no”\n",
    "* 24 features for medications For the generic names: metformin, repaglinide, nateglinide, chlorpropamide, glimepiride, acetohexamide, glipizide, glyburide, tolbutamide, pioglitazone, rosiglitazone, acarbose, miglitol, troglitazone, tolazamide, examide, sitagliptin, insulin, glyburide-metformin, glipizide-metformin, glimepiride- pioglitazone, metformin-rosiglitazone, and metformin- pioglitazone, the feature indicates whether the drug was prescribed or there was a change in the dosage. Values: “up” if the dosage was increased during the encounter, “down” if the dosage was decreased, “steady” if the dosage did not change, and “no” if the drug was not prescribed\n",
    "* ***Readmitted***: Days to inpatient readmission. Values: “<30” if the patient was readmitted in less than 30 days, “>30” if the patient was readmitted in more than 30 days, and “No” for no record of readmission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('diabetic_data.csv', keep_default_na=' ')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_missing_values(dataframe):\n",
    "  '''creates a table with the feature, the total of missing value for the feature, and the percentage'''\n",
    "  df = dataframe\n",
    "  missing_values = pd.DataFrame(index=None, columns= ['feature','quantity','percentage'])\n",
    "  for column in df.columns:\n",
    "    if df[column].dtype == object:\n",
    "      quantity = df[df[column]=='?'][column].count()\n",
    "      percentage = quantity/df[column].count()\n",
    "      missing_values = missing_values.append({\"feature\" : column,\n",
    "                                              \"quantity\" : quantity,\n",
    "                                              \"percentage\": percentage\n",
    "                                              },ignore_index=True)\n",
    "  return missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = get_missing_values(df)\n",
    "missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.gender.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('gender',df[df['gender']=='Unknown/Invalid']['gender'].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop variables with more than 39% of missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_features = missing_values[missing_values['percentage']>= 0.39]['feature']\n",
    "null_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in null_features:\n",
    "  df = df.drop(feature,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to drop rows with \"?\" in any column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_drop = set(df[(df['diag_1'] == '?') & (df['diag_2'] == '?') & (df['diag_3'] == '?')].index)\n",
    "index_to_drop = index_to_drop.union(set(df['diag_1'][df['diag_1'] == '?'].index))\n",
    "index_to_drop = index_to_drop.union(set(df['diag_2'][df['diag_2'] == '?'].index))\n",
    "index_to_drop = index_to_drop.union(set(df['diag_3'][df['diag_3'] == '?'].index))\n",
    "index_to_drop = index_to_drop.union(set(df['race'][df['race'] == '?'].index))\n",
    "index_to_drop = index_to_drop.union(set(df[df['discharge_disposition_id'] == 11].index))#this corresponds to\n",
    "index_to_drop = index_to_drop.union(set(df['gender'][df['gender'] == 'Unknown/Invalid'].index))\n",
    "new_index = list(set(df.index) - set(index_to_drop))\n",
    "df = df.iloc[new_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we are also going to delete this 2 features that has the same value in all rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['citoglipton'].append(df['examide']).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['citoglipton','examide'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Readmitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['readmitted'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.readmitted.value_counts().plot.pie(autopct = \"%.1f%%\")\n",
    "plt.title(\"Proportion of Target Value\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.race.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=df.race, data = df)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Number of Race values\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Proportion of Race\")\n",
    "print(df.race.value_counts(normalize = True)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped_race = {\"Asian\":\"Other\",\"Hispanic\":\"Other\"}\n",
    "#df.race = df.race.replace(mapped_race)\n",
    "\n",
    "sns.countplot(x=df.race.replace(mapped_race), data = df)\n",
    "plt.title(\"Number of Race values\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Proportion of Race After the Mapping\")\n",
    "print(df.race.replace(mapped_race).value_counts(normalize= True)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=\"race\", hue= \"readmitted\", data = df)\n",
    "plt.title(\"Readmitted by Race\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "sns.countplot(y = df['race'], hue = df['readmitted'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x = \"gender\", data = df)\n",
    "plt.title(\"Distribution of Number of Gender\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Proportions of gender\")\n",
    "print(df.gender.value_counts(normalize = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x = \"gender\", hue = \"readmitted\", data = df)\n",
    "plt.title(\"Gender - Readmitted\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=\"age\", data = df)\n",
    "plt.xticks(rotation = 90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.age = df.age.replace({\"[70-80)\":75,\n",
    "                         \"[60-70)\":65,\n",
    "                         \"[50-60)\":55,\n",
    "                         \"[80-90)\":85,\n",
    "                         \"[40-50)\":45,\n",
    "                         \"[30-40)\":35,\n",
    "                         \"[90-100)\":95,\n",
    "                         \"[20-30)\":25,\n",
    "                         \"[10-20)\":15,\n",
    "                         \"[0-10)\":5})\n",
    "\n",
    "sns.countplot(x=\"age\", data = df)\n",
    "#plt.xticks(rotation = 90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,10))\n",
    "sns.countplot(y= df['age'], hue = df['readmitted']).set_title('Age of Patient VS. Readmission')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Admission Type ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* Emergency : 1\n",
    "* Urgent : 2\n",
    "* Elective : 3\n",
    "* Newborn : 4\n",
    "* Not Available : 5\n",
    "* NULL : 6\n",
    "* Trauma Center : 7\n",
    "* Not Mapped : 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x = \"admission_type_id\", data = df)\n",
    "plt.title(\"Distribution of Admission IDs\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Distribution of Admission IDs\")\n",
    "print(df.admission_type_id.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped = {1.0:\"Emergency\",\n",
    "          2.0:\"Emergency\",\n",
    "          3.0:\"Elective\",\n",
    "          4.0:\"New Born\",\n",
    "          5.0:np.nan,\n",
    "          6.0:np.nan,\n",
    "          7.0:\"Trauma Center\",\n",
    "          8.0:np.nan}\n",
    "\n",
    "sns.countplot(x = df.admission_type_id.replace(mapped), data = df)\n",
    "plt.title(\"-Distribution of Admission IDs-\")\n",
    "plt.show()\n",
    "\n",
    "print(\"-Distribution of ID's-\")\n",
    "print(df.admission_type_id.replace(mapped).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.catplot(x = \"admission_type_id\", y =\"readmitted\", \n",
    "                    data = df, height = 6, kind = \"bar\")\n",
    "g.set_ylabels(\"Readmitted Probability\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discharge Disposition ID\n",
    "\n",
    "-Integer identifier corresponding to 29 distinct values. For example, discharged to home, expired, and not available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x =\"discharge_disposition_id\", data = df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Admission Source ID\n",
    "\n",
    "Integer identifier corresponding to 21 distinct values.For example, physician referral, emergency room, and transfer from a hospital"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(df[\"admission_source_id\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* we'll put the similar ones together like Referral or Transfer\n",
    "* we will replace Null, Not Mapped, Unknown values as NAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Readmitted Probability of Referral is very close to Emergency, although Emergency is have more samples than other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Lab Procedures\n",
    "\n",
    "Number of lab tests performed during the encounter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x = \"num_lab_procedures\", data = df)\n",
    "plt.show()\n",
    "\n",
    "print(\"Proportions of Column\")\n",
    "print(df.num_lab_procedures.value_counts().head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time in Hospital VS. Readmission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,8),)\n",
    "ax=sns.kdeplot(df.loc[(df['readmitted'] != '<30'),'time_in_hospital'] , color='g',shade=True,label='Not Readmitted')\n",
    "ax=sns.kdeplot(df.loc[(df['readmitted'] == '<30'),'time_in_hospital'] , color='r',shade=True, label='Readmitted')\n",
    "ax.set(xlabel='Time in Hospital', ylabel='Frequency')\n",
    "plt.title('Time in Hospital VS. Readmission')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of patients stayed 2 - 3 days in hospital"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,5))\n",
    "\n",
    "ax = sns.kdeplot(df.loc[(df.readmitted == 'NO'), \"num_lab_procedures\"],\n",
    "                 color = \"g\", shade = True,label = \"Not Readmitted\")\n",
    "\n",
    "ax = sns.kdeplot(df.loc[(df.readmitted != 'NO'), \"num_lab_procedures\"],\n",
    "                 color = \"r\", shade = True, label = \"Readmitted\")\n",
    "\n",
    "ax.legend(loc=\"upper right\")\n",
    "ax.set_xlabel(\"Number of Lab Procedures\")\n",
    "ax.set_ylabel(\"Frequency\")\n",
    "ax.set_title(\"Number of Lab Procedures - Readmission\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "Number of outpatient visits, number of inpatient visits and  emergency room visits (in the year before the hospitalization) measures how much hospital services a person has used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hospital_service_usage'] = df['number_inpatient'] + df['number_outpatient'] + df['number_emergency']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of medication changes\n",
    "\n",
    "we are going to create a new feature in order to measure the change in the medication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drugs = ['metformin', 'repaglinide', 'nateglinide', 'chlorpropamide', 'glimepiride', 'glipizide', 'glyburide', 'pioglitazone', 'rosiglitazone', 'acarbose', 'miglitol', 'insulin', 'glyburide-metformin', 'tolazamide', 'metformin-pioglitazone','metformin-rosiglitazone', 'glimepiride-pioglitazone', 'glipizide-metformin', 'troglitazone', 'tolbutamide', 'acetohexamide']\n",
    "for col in drugs:\n",
    "    colname = str(col) + 'temp'\n",
    "    df[colname] = df[col].apply(lambda x: 0 if (x == 'No' or x == 'Steady') else 1) # here we care about changes in the drug so put 1 if 'Up' or 'Down'\n",
    "df['numchange'] = 0\n",
    "for col in drugs:\n",
    "    colname = str(col) + 'temp'\n",
    "    df['numchange'] = df['numchange'] + df[colname]\n",
    "    del df[colname]\n",
    "    \n",
    "df['numchange'].value_counts() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can check for the patients with more changes in their drugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.numchange == 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enconding variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.change.unique(), df.gender.unique() ,df.diabetesMed.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['change'] = df['change'].replace('Ch', 1)\n",
    "df['change'] = df['change'].replace('No', 0)\n",
    "df['gender'] = df['gender'].replace('Male', 1)\n",
    "df['gender'] = df['gender'].replace('Female', 0)\n",
    "df['diabetesMed'] = df['diabetesMed'].replace('Yes', 1)\n",
    "df['diabetesMed'] = df['diabetesMed'].replace('No', 0)\n",
    "# drugs is the same as before\n",
    "for col in drugs: #here we care about having or not the drug\n",
    "    df[col] = df[col].replace('No', 0)\n",
    "    df[col] = df[col].replace('Steady', 1)\n",
    "    df[col] = df[col].replace('Up', 1)\n",
    "    df[col] = df[col].replace('Down', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also reduced both A1C test result and Glucose serum test result into categories of Normal, Abnormal and Not tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.A1Cresult.unique(), df.max_glu_serum.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['A1Cresult'] = df['A1Cresult'].replace('>7', 1)\n",
    "df['A1Cresult'] = df['A1Cresult'].replace('>8', 1)\n",
    "df['A1Cresult'] = df['A1Cresult'].replace('Norm', 0)\n",
    "df['A1Cresult'] = df['A1Cresult'].replace('None', -99)\n",
    "df['max_glu_serum'] = df['max_glu_serum'].replace('>200', 1)\n",
    "df['max_glu_serum'] = df['max_glu_serum'].replace('>300', 1)\n",
    "df['max_glu_serum'] = df['max_glu_serum'].replace('Norm', 0)\n",
    "df['max_glu_serum'] = df['max_glu_serum'].replace('None', -99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some patients in the dataset had more than one encounter, we can't count them as independent encounters cause that is going to bias the result towards those who had several encounters.\n",
    "\n",
    "We can considered the first and last encounter separately as possible representations of multiple encounters. So we are going to evaluate the balance of the data in order to see wich aproach is better\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Readmissions vs No Readmissions using this approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are primarily interested in factors that lead to early readmission, we defined the readmission attribute (outcome) as having two values: “readmitted,” if the patient was readmitted within 30 days of discharge or “otherwise,” which covers both readmission after 30 days and no readmission at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keeping the last encounter\n",
    "duplicated_last_approach = df[df.duplicated(subset=['patient_nbr'], keep='last')]\n",
    "len(duplicated_last_approach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_encounter_readmission = duplicated_last_approach[duplicated_last_approach['readmitted'] == '<30']\n",
    "len(last_encounter_readmission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage_of_readmission = len(last_encounter_readmission)/len(duplicated_last_approach)\n",
    "print(f'keeping the last encounters we get {len(duplicated_last_approach)} records for which {round(percentage_of_readmission * 100)} % of patients has been readmitted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keeping the first encounter\n",
    "duplicated_first_approach = df[df.duplicated(subset=['patient_nbr'], keep='first')]\n",
    "len(duplicated_first_approach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_encounter_readmission = duplicated_first_approach[duplicated_first_approach['readmitted'] == '<30']\n",
    "len(first_encounter_readmission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage_of_readmission = len(first_encounter_readmission)/len(duplicated_first_approach)\n",
    "print(f'keeping the first encounters we get {len(duplicated_first_approach)} records for which {round(percentage_of_readmission * 100)} % of patients has been readmitted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the last encounters approach we end up with a less imbalanced data for readmissions (27/73 Readmissions vs No Readmissions) and so we are going to use last encounters of patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset= ['patient_nbr'], keep = 'last')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['readmitted'] = df['readmitted'].replace('>30', 0)\n",
    "df['readmitted'] = df['readmitted'].replace('<30', 1)\n",
    "df['readmitted'] = df['readmitted'].replace('NO', 0)\n",
    "\n",
    "df.readmitted.value_counts().plot.pie(autopct = \"%.1f%%\")\n",
    "plt.title(\"Proportion of Target Value\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Modeling Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data type of nominal features in dataframe to 'object' type\n",
    "i = ['encounter_id', 'patient_nbr', 'gender', 'admission_type_id', 'discharge_disposition_id', 'admission_source_id',\\\n",
    "          'A1Cresult', 'metformin', 'repaglinide', 'nateglinide', 'chlorpropamide', 'glimepiride', 'acetohexamide', \\\n",
    "          'glipizide', 'glyburide', 'tolbutamide', 'pioglitazone', 'rosiglitazone', 'acarbose','miglitol', \\\n",
    "          'troglitazone', 'tolazamide', 'insulin', 'glyburide-metformin', 'glipizide-metformin', \\\n",
    "          'glimepiride-pioglitazone', 'metformin-rosiglitazone', 'metformin-pioglitazone', 'change', 'diabetesMed', \\\n",
    "          'age', 'A1Cresult', 'max_glu_serum']\n",
    "\n",
    "df[i] = df[i].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of medication used\n",
    "df['num_med'] = 0\n",
    "\n",
    "for col in drugs:\n",
    "    df['num_med'] = df['num_med'] + df[col]\n",
    "df['num_med'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of only numeric features\n",
    "num_col = list(set(list(df._get_numeric_data().columns))- {'readmitted'})\n",
    "num_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing skewnewss and kurtosis using log transformation if it is above a threshold value -  2\n",
    "\n",
    "statdataframe = pd.DataFrame()\n",
    "statdataframe['numeric_column'] = num_col\n",
    "skew_before = []\n",
    "skew_after = []\n",
    "\n",
    "kurt_before = []\n",
    "kurt_after = []\n",
    "\n",
    "standard_deviation_before = []\n",
    "standard_deviation_after = []\n",
    "\n",
    "log_transform_needed = []\n",
    "\n",
    "log_type = []\n",
    "\n",
    "for i in num_col:\n",
    "    skewval = df[i].skew()\n",
    "    skew_before.append(skewval)\n",
    "    \n",
    "    kurtval = df[i].kurtosis()\n",
    "    kurt_before.append(kurtval)\n",
    "    \n",
    "    sdval = df[i].std()\n",
    "    standard_deviation_before.append(sdval)\n",
    "    \n",
    "    if (abs(skewval) >2) & (abs(kurtval) >2):\n",
    "        log_transform_needed.append('Yes')\n",
    "        \n",
    "        if len(df[df[i] == 0])/len(df) <=0.02:\n",
    "            log_type.append('log')\n",
    "            skewvalnew = np.log(pd.DataFrame(df[train_data[i] > 0])[i]).skew()\n",
    "            skew_after.append(skewvalnew)\n",
    "            \n",
    "            kurtvalnew = np.log(pd.DataFrame(df[train_data[i] > 0])[i]).kurtosis()\n",
    "            kurt_after.append(kurtvalnew)\n",
    "            \n",
    "            sdvalnew = np.log(pd.DataFrame(df[train_data[i] > 0])[i]).std()\n",
    "            standard_deviation_after.append(sdvalnew)\n",
    "            \n",
    "        else:\n",
    "            log_type.append('log1p')\n",
    "            skewvalnew = np.log1p(pd.DataFrame(df[df[i] >= 0])[i]).skew()\n",
    "            skew_after.append(skewvalnew)\n",
    "        \n",
    "            kurtvalnew = np.log1p(pd.DataFrame(df[df[i] >= 0])[i]).kurtosis()\n",
    "            kurt_after.append(kurtvalnew)\n",
    "            \n",
    "            sdvalnew = np.log1p(pd.DataFrame(df[df[i] >= 0])[i]).std()\n",
    "            standard_deviation_after.append(sdvalnew)\n",
    "            \n",
    "    else:\n",
    "        log_type.append('NA')\n",
    "        log_transform_needed.append('No')\n",
    "        \n",
    "        skew_after.append(skewval)\n",
    "        kurt_after.append(kurtval)\n",
    "        standard_deviation_after.append(sdval)\n",
    "\n",
    "statdataframe['skew_before'] = skew_before\n",
    "statdataframe['kurtosis_before'] = kurt_before\n",
    "statdataframe['standard_deviation_before'] = standard_deviation_before\n",
    "statdataframe['log_transform_needed'] = log_transform_needed\n",
    "statdataframe['log_type'] = log_type\n",
    "statdataframe['skew_after'] = skew_after\n",
    "statdataframe['kurtosis_after'] = kurt_after\n",
    "statdataframe['standard_deviation_after'] = standard_deviation_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statdataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform log transformation.\n",
    "\n",
    "for i in range(len(statdataframe)):\n",
    "    if statdataframe['log_transform_needed'][i] == 'Yes':\n",
    "        colname = str(statdataframe['numeric_column'][i])\n",
    "        \n",
    "        if statdataframe['log_type'][i] == 'log':\n",
    "            df = df[df[colname] > 0]\n",
    "            df[colname + \"_log\"] = np.log(df[colname])\n",
    "            \n",
    "        elif statdataframe['log_type'][i] == 'log1p':\n",
    "            df = df[df[colname] >= 0]\n",
    "            df[colname + \"_log1p\"] = np.log1p(df[colname])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop columns with no tranformation\n",
    "df = df.drop(['number_outpatient', 'number_inpatient', 'number_emergency','hospital_service_usage'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of only numeric features\n",
    "numerics = list(set(list(df._get_numeric_data().columns))- {'readmitted'})\n",
    "numerics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# covariance - uses spearman rank covariance coeff.\n",
    "sns.heatmap(df[numerics].corr(), annot =  True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bivariate analysis of related features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "\n",
    "#number of emergency visit/hospital usage\n",
    "var = 'number_emergency_log1p'\n",
    "data = pd.concat([df['hospital_service_usage_log1p'], df[var]], axis=1)\n",
    "data.plot.scatter(x=var, y='hospital_service_usage_log1p');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of inpatient visit/hospital usage\n",
    "var = 'number_inpatient_log1p'\n",
    "data = pd.concat([df['hospital_service_usage_log1p'], df[var]], axis=1)\n",
    "data.plot.scatter(x=var, y='hospital_service_usage_log1p');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of outpatient visit/hospital usage\n",
    "var = 'number_outpatient_log1p'\n",
    "data = pd.concat([df['hospital_service_usage_log1p'], df[var]], axis=1)\n",
    "data.plot.scatter(x=var, y='hospital_service_usage_log1p');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show list of features that are categorical\n",
    "df.encounter_id = df.encounter_id.astype('int64')\n",
    "df.patient_nbr = df.patient_nbr.astype('int64')\n",
    "df.diabetesMed = df.diabetesMed.astype('int64')\n",
    "df.change = df.change.astype('int64')\n",
    "\n",
    "# convert data type of nominal features in dataframe to 'object' type for aggregating\n",
    "i = ['metformin', 'repaglinide', 'nateglinide', 'chlorpropamide', 'glimepiride', 'acetohexamide', \\\n",
    "          'glipizide', 'glyburide', 'tolbutamide','pioglitazone', 'rosiglitazone', 'acarbose','miglitol', \\\n",
    "          'troglitazone', 'tolazamide','insulin', 'glyburide-metformin', 'glipizide-metformin', \\\n",
    "          'glimepiride-pioglitazone','metformin-rosiglitazone', 'metformin-pioglitazone','A1Cresult']\n",
    "df[i] = df[i].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcopy = df.copy(deep = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "# transform data\n",
    "scaled = scaler.fit_transform(df[numerics])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[numerics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_num_cols = ['race', 'gender', 'admission_type_id', 'discharge_disposition_id', 'admission_source_id', \n",
    "                'max_glu_serum', 'A1Cresult' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_cols = list(set(list(df._get_numeric_data().columns))- {'readmitted', 'change'})\n",
    "# len(num_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encoder - variables with many categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how many categories each variable has\n",
    "for col in df[non_num_cols]:\n",
    "    print(f'{col}: {len(df[col].unique())} categories')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features 'discharge_disposition_id' and 'admission_source_id' have lot of categories, if we use one hot encoding we end up with 40 new features.\n",
    "\n",
    "In the winning solution of the KDD 2009 cup: Winning the KDD Cup Orange Challenge with Ensemble Selection the authors limit one hot encoding to the 10 most frequent labels only. This is equivalent to grouping all the other labels under a new category, that in this case will be dropped. Thus, the 10 new dummies variables indicate if one of the 10 most frequent labels is present(1) or not (0) for a particular observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#lets find the top 10 most frequent categories for the variable discharge_disposition_id\n",
    "df.discharge_disposition_id.value_counts().sort_values(ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets make a list with the most frequent categories of the variable\n",
    "top_10_dd = [ x for x in df.discharge_disposition_id.value_counts().sort_values(ascending=False).head(10).index]\n",
    "top_10_dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and now we make the 10 binary variables\n",
    "for label in top_10_dd:\n",
    "  df['discharge_disposition_id'+'_'+ str(label)]= np.where(df['discharge_disposition_id']==label,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns= ['discharge_disposition_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same process for admission_source_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_as = [ x for x in df.admission_source_id.value_counts().sort_values(ascending=False).head(10).index]\n",
    "top_10_as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label_ in top_10_dd:\n",
    "  df['admission_source_id'+'_'+ str(label_)]= np.where(df['admission_source_id']==label_,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns= ['admission_source_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns= ['encounter_id','patient_nbr','diag_1','diag_2','diag_3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.A1Cresult.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#showing some columns\n",
    "df.iloc[:10,37:47]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df,columns=['race', 'admission_type_id',\n",
    "                                                   'max_glu_serum', 'A1Cresult' ],drop_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.readmitted.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.loc[:, ~df.columns.isin(['readmitted'])]\n",
    "y = df['readmitted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['readmitted'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)\n",
    "logit = LogisticRegression(fit_intercept=True, penalty='l2',solver='lbfgs', max_iter=1000) \n",
    "logit.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_pred = logit.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cmtx = pd.DataFrame(\n",
    "    confusion_matrix(y_test, logit_pred), \n",
    "    index=['actual:0', 'actual:1'], \n",
    "    columns=['pred:0', 'pred:1']\n",
    ")\n",
    "print(cmtx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score , f1_score\n",
    "print(f'Accuracy is {accuracy_score(y_test, logit_pred):.2f}')\n",
    "print(f'Precision is {precision_score(y_test, logit_pred):.2f}')\n",
    "print(f'Recall is {recall_score(y_test, logit_pred):.2f}')\n",
    "print(f'f1Score is {f1_score(y_test, logit_pred):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our target variable is having class imbalance problem, So will use SMOTE technique to resolve it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "print(f'Original dataset shape {Counter(y_train)}')\n",
    "sm = SMOTE(random_state=20)\n",
    "train_input_new, train_output_new = sm.fit_resample(X_train, y_train)\n",
    "print(f'New dataset shape {Counter(train_output_new)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_new = pd.DataFrame(train_input_new, columns = list(X.columns))\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_input_new, train_output_new, test_size=0.20, random_state=0)\n",
    "logit = LogisticRegression(fit_intercept=True, penalty='l2')\n",
    "logit.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_pred = logit.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmtx = pd.DataFrame(\n",
    "    confusion_matrix(y_test, logit_pred), \n",
    "    index=['actual:0', 'actual:1'], \n",
    "    columns=['pred:0', 'pred:1']\n",
    ")\n",
    "print(cmtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy is {accuracy_score(y_test, logit_pred):.2f}\")\n",
    "print(f\"Precision is {precision_score(y_test, logit_pred):.2f}\")\n",
    "print(f\"Recall is {recall_score(y_test, logit_pred):.2f}\")\n",
    "print(f\"f1Score is {f1_score(y_test, logit_pred):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to give more importance to Recall because we consider more relevant to detect correctly the cases when the patient need to be readmitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df._get_numeric_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_set_no_int = ['age', 'time_in_hospital', 'num_procedures', 'num_medications', 'number_outpatient_log1p', \n",
    "                 'number_emergency_log1p', 'number_inpatient_log1p', 'number_diagnoses', 'metformin', \n",
    "                 'repaglinide', 'nateglinide', 'chlorpropamide', 'glimepiride', 'glipizide', \n",
    "                 'glyburide', 'pioglitazone', 'rosiglitazone', 'acarbose', \n",
    "                 'tolazamide', 'insulin', 'glyburide-metformin',\n",
    "                 'AfricanAmerican', 'Asian', 'Caucasian', \n",
    "                 'Hispanic', 'Other', 'gender_1', \n",
    "                 'admission_type_id_3', 'admission_type_id_5', \n",
    "                 'discharge_disposition_id_2', 'discharge_disposition_id_7', \n",
    "                 'discharge_disposition_id_10', 'discharge_disposition_id_18', \n",
    "                 'admission_source_id_4', 'admission_source_id_7', \n",
    "                 'admission_source_id_9', 'max_glu_serum_0', \n",
    "                 'max_glu_serum_1', 'A1Cresult_0', 'A1Cresult_1', \n",
    "                 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Original dataset shape {Counter(y)}')\n",
    "smt = SMOTE(random_state=20)\n",
    "train_input_new, train_output_new = smt.fit_resample(X, y)\n",
    "print(f'New dataset shape {Counter(train_output_new)}')\n",
    "train_input_new = pd.DataFrame(train_input_new, columns = list(X.columns))\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_input_new, train_output_new, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtree = DecisionTreeClassifier(max_depth=28, criterion = \"entropy\", min_samples_split=10)\n",
    "dtree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree_pred = dtree.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmtx = pd.DataFrame(\n",
    "    confusion_matrix(y_test, dtree_pred), \n",
    "    index=['actual:0', 'actual:1'], \n",
    "    columns=['pred:0', 'pred:1']\n",
    ")\n",
    "print(cmtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy is {accuracy_score(y_test, dtree_pred):.2f}\")\n",
    "print(f\"Precision is {precision_score(y_test, dtree_pred):.2f}\")\n",
    "print(f\"Recall is {recall_score(y_test, dtree_pred):.2f}\")\n",
    "print(f\"f1Score is {f1_score(y_test, dtree_pred):.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features with most impact\n",
    "feature_names = X_train.columns\n",
    "feature_imports = dtree.feature_importances_\n",
    "most_imp_features = pd.DataFrame([f for f in zip(feature_names,feature_imports)], columns=[\"Feature\", \"Importance\"]).nlargest(10, \"Importance\")\n",
    "most_imp_features.sort_values(by=\"Importance\", inplace=True)\n",
    "print(most_imp_features)\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.barh(range(len(most_imp_features)), most_imp_features.Importance, align='center', alpha=0.8)\n",
    "plt.yticks(range(len(most_imp_features)), most_imp_features.Feature, fontsize=14)\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Most important features - Decision Tree')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Original dataset shape {Counter(y)}')\n",
    "smt = SMOTE(random_state=20)\n",
    "train_input_new, train_output_new = smt.fit_resample(X, y)\n",
    "print(f'New dataset shape {Counter(train_output_new)}')\n",
    "train_input_new = pd.DataFrame(train_input_new, columns = list(X.columns))\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_input_new, train_output_new, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rm = RandomForestClassifier(n_estimators = 10, max_depth=25, criterion = \"gini\", min_samples_split=10)\n",
    "rm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm_prd = rm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmtx = pd.DataFrame(\n",
    "    confusion_matrix(y_test, rm_prd), \n",
    "    index=['actual:0', 'actual:1'], \n",
    "    columns=['pred:0', 'pred:1']\n",
    ")\n",
    "print(cmtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy is {accuracy_score(y_test, rm_prd):.2f}\")\n",
    "print(f\"Precision is {precision_score(y_test, rm_prd):.2f}\")\n",
    "print(f\"Recall is {recall_score(y_test, rm_prd):.2f}\")\n",
    "print(f\"f1Score is {f1_score(y_test, rm_prd):.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features with most impact\n",
    "feature_names = X_train.columns\n",
    "feature_imports = rm.feature_importances_\n",
    "most_imp_features = pd.DataFrame([f for f in zip(feature_names,feature_imports)], columns=[\"Feature\", \"Importance\"]).nlargest(10, \"Importance\")\n",
    "most_imp_features.sort_values(by=\"Importance\", inplace=True)\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.barh(range(len(most_imp_features)), most_imp_features.Importance, align='center', alpha=0.8)\n",
    "plt.yticks(range(len(most_imp_features)), most_imp_features.Feature, fontsize=14)\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Most important features - Random Forest ')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "# calculate the fpr and tpr for all thresholds of the classification\n",
    "probs = rm.predict_proba(X_test)\n",
    "preds = probs[:,1]\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "# plotting the curve\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = f'AUC = {roc_auc:.2f}')\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([-0.01, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The closer the curve reaching point 1 on the top left of the curve, the better the model is since we maximize correct predictions and minimize incorrect ones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before proceding we need to change the object type columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_columns = X.loc[:, df.dtypes == object].columns\n",
    "object_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in object_columns:\n",
    "    print(col)\n",
    "    X[col] = pd.to_numeric(X[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "smt = SMOTE(random_state=20)\n",
    "train_input_new, train_output_new = smt.fit_resample(X, y)\n",
    "print(f'New dataset shape {Counter(train_output_new)}')\n",
    "train_input_new = pd.DataFrame(train_input_new, columns = list(X.columns))\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_input_new, train_output_new, test_size=0.20, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBClassifier(max_depth=10,n_estimators=100)\n",
    "xgb_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_pred=xgb_model.predict(X_test)\n",
    "xgb_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmtx = pd.DataFrame(\n",
    "    confusion_matrix(y_test, xgb_pred), \n",
    "    index=['actual:0', 'actual:1'], \n",
    "    columns=['pred:0', 'pred:1']\n",
    ")\n",
    "print(cmtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy is {accuracy_score(y_test, xgb_pred):.2f}\")\n",
    "print(f\"Precision is {precision_score(y_test, xgb_pred):.2f}\")\n",
    "print(f\"Recall is {recall_score(y_test, xgb_pred):.2f}\")\n",
    "print(f\"f1Score is {f1_score(y_test, xgb_pred):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features with most impact\n",
    "feature_names = X_train.columns\n",
    "feature_imports = xgb_model.feature_importances_\n",
    "most_imp_features = pd.DataFrame([f for f in zip(feature_names,feature_imports)], columns=[\"Feature\", \"Importance\"]).nlargest(10, \"Importance\")\n",
    "most_imp_features.sort_values(by=\"Importance\", inplace=True)\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.barh(range(len(most_imp_features)), most_imp_features.Importance, align='center', alpha=0.8)\n",
    "plt.yticks(range(len(most_imp_features)), most_imp_features.Feature, fontsize=14)\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Most important features - XGB Classifier ')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Model\n",
    "model = Sequential()\n",
    "model.add(Dense(4, input_dim=71, activation='relu', name = 'input_layer'))\n",
    "model.add(Dense(10, activation='relu', name = 'hidden_layer'))\n",
    "model.add(Dense(1, activation='sigmoid', name = 'output_layer'))\n",
    "\n",
    "# Compile\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Fit\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=25)\n",
    "\n",
    "# Evaluation\n",
    "scores = model.evaluate(X_train, y_train)\n",
    "print(f'\\n{model.metrics_names[1]}: {(scores[1]*100):.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rounded = [round(z[0]) for z in nn_pred]\n",
    "nn_pred = rounded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmtx = pd.DataFrame(\n",
    "    confusion_matrix(y_test, nn_pred), \n",
    "    index=['actual:0', 'actual:1'], \n",
    "    columns=['pred:0', 'pred:1']\n",
    ")\n",
    "print(cmtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy is {accuracy_score(y_test, nn_pred):.2f}\")\n",
    "print(f\"Precision is {precision_score(y_test, nn_pred):.2f}\")\n",
    "print(f\"Recall is {recall_score(y_test, nn_pred):.2f}\")\n",
    "print(f\"f1Score is {f1_score(y_test, nn_pred):.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
